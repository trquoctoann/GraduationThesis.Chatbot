{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from joblib import dump\n",
    "from itertools import chain\n",
    "from sklearn_crfsuite import CRF\n",
    "from utils.preprocessing import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerInfoCRFModel:\n",
    "    def __init__(self):\n",
    "        self.model = CRF(\n",
    "            algorithm='lbfgs',\n",
    "            c1=0.1,\n",
    "            c2=0.1,\n",
    "            max_iterations=100,\n",
    "            all_possible_transitions=True\n",
    "        )\n",
    "        self.labels = ['B-Quantity', 'B-Pizza', 'I-Pizza', 'B-Topping', 'B-Size', 'I-Size', 'O', 'B-Crust', 'I-Crust']\n",
    "    \n",
    "    def word2features(self, sentence, i):\n",
    "        word = sentence[i]\n",
    "        features = {\n",
    "            'bias': 1.0,\n",
    "            'word.lower()': word.lower(),\n",
    "            'word[-3:]': word[-3:],\n",
    "            'word[-2:]': word[-2:],\n",
    "            'word.isupper()': word.isupper(),\n",
    "            'word.isdigit()': word.isdigit(),\n",
    "        }\n",
    "        if i > 0:\n",
    "            word1 = sentence[i-1]\n",
    "            features.update({\n",
    "                '-1:word.lower()': word1.lower(),\n",
    "                '-1:word.isupper()': word1.isupper(),\n",
    "                '-1:word.isdigit()': word1.isdigit(),\n",
    "            })\n",
    "        else:\n",
    "            features['BOS'] = True\n",
    "\n",
    "        if i < len(sentence)-1:\n",
    "            word1 = sentence[i+1]\n",
    "            features.update({\n",
    "                '+1:word.lower()': word1.lower(),\n",
    "                '+1:word.isupper()': word1.isupper(),\n",
    "                '+1:word.isdigit()': word1.isdigit(),\n",
    "            })\n",
    "        else:\n",
    "            features['EOS'] = True\n",
    "            \n",
    "        return features\n",
    "\n",
    "    def sentence_features(self, words):\n",
    "        return [self.word2features(words, i) for i in range(len(words))]\n",
    "\n",
    "    def sentence_labels(self, labels):\n",
    "        return labels\n",
    "\n",
    "    def load_data_from_json(self, file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        return [(\n",
    "            item['words'], \n",
    "            item['label']\n",
    "        ) for item in data]\n",
    "\n",
    "    def train(self, data):\n",
    "        X = [self.sentence_features(s[0]) for s in data]\n",
    "        y = [self.sentence_labels(s[1]) for s in data]\n",
    "\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def process_sentence(self, sentence):\n",
    "        tokens = re.findall(r\"[\\w']+|[.,!?;]\", sentence)\n",
    "        return {\n",
    "            \"words\": tokens,\n",
    "            \"label\": [\"O\"] * len(tokens),\n",
    "        }\n",
    "\n",
    "    def predict(self, text):\n",
    "        processed_sentence = self.process_sentence(text)\n",
    "        words = processed_sentence[\"words\"]\n",
    "        features = self.sentence_features(words)\n",
    "\n",
    "        labels = self.model.predict([features])[0]\n",
    "\n",
    "        result = {\n",
    "            \"words\": words,\n",
    "            \"label\": labels,\n",
    "        }\n",
    "        return self.aggregate_entities(result)\n",
    "    \n",
    "    def predict_with_confidence(self, text):\n",
    "        processed_sentence = self.process_sentence(text)\n",
    "        words = processed_sentence[\"words\"]\n",
    "        features = self.sentence_features(words)\n",
    "\n",
    "        labels_with_confidence = self.model.predict_marginals([features])[0]\n",
    "\n",
    "        result = []\n",
    "        for word, word_labels in zip(words, labels_with_confidence):\n",
    "            best_label, best_confidence = max(word_labels.items(), key=lambda item: item[1])\n",
    "            result.append((word, best_label, best_confidence))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def aggregate_entities(self, predicted_result):\n",
    "        aggregated_entities = {}\n",
    "        current_entity = None\n",
    "        current_label = None\n",
    "\n",
    "        for word, label in zip(predicted_result[\"words\"], predicted_result[\"label\"]):\n",
    "            if label.startswith(\"B-\"):\n",
    "                if current_entity is not None and current_label is not None:\n",
    "                    if current_label in aggregated_entities:\n",
    "                        aggregated_entities[current_label].append(\" \".join(current_entity))\n",
    "                    else:\n",
    "                        aggregated_entities[current_label] = [\" \".join(current_entity)]\n",
    "                \n",
    "                current_entity = [word]\n",
    "                current_label = label[2:] \n",
    "            elif label.startswith(\"I-\") and current_entity is not None and label[2:] == current_label:\n",
    "                current_entity.append(word)\n",
    "            else:\n",
    "                if current_entity is not None and current_label is not None:\n",
    "                    if current_label in aggregated_entities:\n",
    "                        aggregated_entities[current_label].append(\" \".join(current_entity))\n",
    "                    else:\n",
    "                        aggregated_entities[current_label] = [\" \".join(current_entity)]\n",
    "                    current_entity = None\n",
    "                    current_label = None\n",
    "                if label == \"O\":\n",
    "                    continue\n",
    "                else:\n",
    "                    aggregated_entities[label] = aggregated_entities.get(label, []) + [word]\n",
    "\n",
    "        if current_entity is not None and current_label is not None:\n",
    "            if current_label in aggregated_entities:\n",
    "                aggregated_entities[current_label].append(\" \".join(current_entity))\n",
    "            else:\n",
    "                aggregated_entities[current_label] = [\" \".join(current_entity)]\n",
    "\n",
    "        return aggregated_entities\n",
    "\n",
    "    def save_model(self, file_path):\n",
    "        dump(self.model, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomerInfoCRFModel()\n",
    "data = model.load_data_from_json('../data/labeled/entity/order/final_data.json')\n",
    "model.train(data)\n",
    "model.save_model(\"order_entity_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
