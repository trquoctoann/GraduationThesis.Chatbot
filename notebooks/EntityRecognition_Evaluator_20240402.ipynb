{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRFEvaluator:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.labels = ['B-Quantity', 'B-Pizza', 'I-Pizza', 'B-Topping', 'B-Size', 'I-Size', 'O', 'B-Crust', 'I-Crust']\n",
    "\n",
    "    def evaluate(self, test_data, evaluation_type):\n",
    "        if evaluation_type == 'confusion_matrix':\n",
    "            self._plot_confusion_matrix(test_data)\n",
    "        elif evaluation_type == 'classification_report':\n",
    "            self._print_classification_report(test_data)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported evaluation type. Supported types are 'confusion_matrix' and 'classification_report'.\")\n",
    "\n",
    "    def _confusion_matrix(self, test_data):\n",
    "        y_test, y_pred = self._get_predictions(test_data)\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=self.labels)\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=\"Blues\", xticklabels=self.labels, yticklabels=self.labels)\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "    def _classification_report(self, test_data):\n",
    "        y_test, y_pred = self._get_predictions(test_data)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, labels=self.labels, zero_division=0)\n",
    "        \n",
    "        x = np.arange(len(self.labels))\n",
    "        width = 0.3\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        rects1 = ax.bar(x - width, precision, width, label='Precision')\n",
    "        rects2 = ax.bar(x, recall, width, label='Recall')\n",
    "        rects3 = ax.bar(x + width, f1, width, label='F1-score')\n",
    "\n",
    "        ax.set_ylabel('Scores')\n",
    "        ax.set_title('Scores by group and evaluation metric')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(self.labels, rotation=45, ha='right')\n",
    "        ax.legend()\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
